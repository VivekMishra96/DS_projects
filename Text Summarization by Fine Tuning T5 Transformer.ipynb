{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab2424-4b5e-4263-83a5-b274ffed42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers accelerate==0.21.0 datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525429f-8b13-4420-8e93-8e527864e176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c381c763-f4fa-4a9d-81d6-ed350d49dd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce1178fb45b4434a06e2d6a4d97101c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2bd777-c3df-408e-a877-cff73870b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q 'news_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d62ab3b-3c19-49fc-b9b9-0282f125b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 25 10:57:27 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                        Off| 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   57C    P8               13W /  70W|      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4                        Off| 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   56C    P8               11W /  70W|      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4                        Off| 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   62C    P8               13W /  70W|      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4                        Off| 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   61C    P8               12W /  70W|      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5774d2e8-300b-4055-bc0a-9a66ca9eb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347f1371-947a-454a-952a-b737c967c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'BBC News Summary/News Articles/sport'\n",
    "\n",
    "file_names = []\n",
    "file_contents = []\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_names.append(file_name)\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            content = file.read().decode(errors='ignore')\n",
    "            file_contents.append(content)\n",
    "\n",
    "data = {'File_Name': file_names, 'News': file_contents}\n",
    "df1 = pd.DataFrame(data)\n",
    "file_names = []\n",
    "file_contents = []\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_names.append(file_name)\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            content = file.read().decode(errors='ignore')\n",
    "            file_contents.append(content)\n",
    "\n",
    "data = {'File_Name': file_names, 'News': file_contents}\n",
    "df1 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466d32b4-b209-45e1-9878-fa41fd5b9c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hantuchova in Dubai last eight\\n\\nDaniela Hantuchova moved into the quarter-finals of the Dubai Open, after beating Elene Likhotseva of Russia 7-5 6-4, and now faces Serena Williams.\\n\\nAustralian Open champion Williams survived an early scare to beat Russia\\'s Elena Bovina 1-6 6-1 6-4. World number one Lindsay Davenport and Anastasia Myskina also progressed. Davenport defeated China\\'s Jie Zheng 6-2 7-5, while French Open champion Myskina sailed through after her opponent Marion Bartoli retired hurt. American Davenport will now face fellow former Wimbledon champion, Conchita Martinez of Spain, who ousted seventh-seeded Nathalie Dechy of France 6-1 6-2. Myskina will face eighth-seed Patty Schnyder from Switzerland, who defeated China\\'s Li Na 6-3 7-6 (10-8). The other quarter final pits wild card Sania Mirza of India against Jelena Jankovic of Serbia and Montenegro, who both won on Tuesday.\\n\\nBefore her meeting with Martinez, Davenport believes there is some room for improvement in her game. \"I started well and finished well, but played some so-so games in the middle,\" she said. Williams was also far from content. \"I don\\'t know what I was doing there,\" she said. \"It was really windy and I hadn\\'t played in the wind. All my shots were going out of here.\" But Hantuchova is in upbeat mood ahead of her clash with the younger Williams sister, who was handed a first-round bye. \"I feel I have an advantage (over Serena) because I have already played two matches on these courts,\" she said. \"It is a difficult court to play on. Very fast and sometimes you feel you have no control over the ball.\"\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['News'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6ee184-32cc-4631-9a0f-ae5b967b5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'BBC News Summary/Summaries/sport'\n",
    "file_names = []\n",
    "file_contents = []\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_names.append(file_name)\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            content = file.read().decode(errors='ignore')\n",
    "            file_contents.append(content)\n",
    "            \n",
    "data = {'File_Name': file_names, 'Summary': file_contents}\n",
    "df2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5743e4de-eb0d-4021-9baa-61782eb144cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Williams was also far from content.Davenport defeated China\\'s Jie Zheng 6-2 7-5, while French Open champion Myskina sailed through after her opponent Marion Bartoli retired hurt.\"I don\\'t know what I was doing there,\" she said.\"I feel I have an advantage (over Serena) because I have already played two matches on these courts,\" she said.Daniela Hantuchova moved into the quarter-finals of the Dubai Open, after beating Elene Likhotseva of Russia 7-5 6-4, and now faces Serena Williams.\"It was really windy and I hadn\\'t played in the wind.But Hantuchova is in upbeat mood ahead of her clash with the younger Williams sister, who was handed a first-round bye.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Summary'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1168aa4d-5881-433a-a861-9c5a39896e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robinson answers critics\\n\\nEngland captain Ja...</td>\n",
       "      <td>Robinson said: \"We are certainly not on the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isinbayeva claims new world best\\n\\nPole vault...</td>\n",
       "      <td>In the men's 60m, former Olympic 100m champion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Klinsmann issues Lehmann warning\\n\\nGermany co...</td>\n",
       "      <td>Klinsmann added: \"If he is not playing regular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hantuchova in Dubai last eight\\n\\nDaniela Hant...</td>\n",
       "      <td>Williams was also far from content.Davenport d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greek duo cleared in doping case\\n\\nSprinters ...</td>\n",
       "      <td>Kenteris's lawyer, Gregory Ioannidis, said: \"T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  \\\n",
       "0  Robinson answers critics\\n\\nEngland captain Ja...   \n",
       "1  Isinbayeva claims new world best\\n\\nPole vault...   \n",
       "2  Klinsmann issues Lehmann warning\\n\\nGermany co...   \n",
       "3  Hantuchova in Dubai last eight\\n\\nDaniela Hant...   \n",
       "4  Greek duo cleared in doping case\\n\\nSprinters ...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Robinson said: \"We are certainly not on the de...  \n",
       "1  In the men's 60m, former Olympic 100m champion...  \n",
       "2  Klinsmann added: \"If he is not playing regular...  \n",
       "3  Williams was also far from content.Davenport d...  \n",
       "4  Kenteris's lawyer, Gregory Ioannidis, said: \"T...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df1, df2, on='File_Name').drop(['File_Name'], axis= 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4456143-32db-4a8e-af1c-ed0270a2bc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robinson answers critics\\n\\nEngland captain Ja...</td>\n",
       "      <td>Robinson said: \"We are certainly not on the de...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isinbayeva claims new world best\\n\\nPole vault...</td>\n",
       "      <td>In the men's 60m, former Olympic 100m champion...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Klinsmann issues Lehmann warning\\n\\nGermany co...</td>\n",
       "      <td>Klinsmann added: \"If he is not playing regular...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hantuchova in Dubai last eight\\n\\nDaniela Hant...</td>\n",
       "      <td>Williams was also far from content.Davenport d...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greek duo cleared in doping case\\n\\nSprinters ...</td>\n",
       "      <td>Kenteris's lawyer, Gregory Ioannidis, said: \"T...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  \\\n",
       "0  Robinson answers critics\\n\\nEngland captain Ja...   \n",
       "1  Isinbayeva claims new world best\\n\\nPole vault...   \n",
       "2  Klinsmann issues Lehmann warning\\n\\nGermany co...   \n",
       "3  Hantuchova in Dubai last eight\\n\\nDaniela Hant...   \n",
       "4  Greek duo cleared in doping case\\n\\nSprinters ...   \n",
       "\n",
       "                                             Summary   Title  \n",
       "0  Robinson said: \"We are certainly not on the de...  sports  \n",
       "1  In the men's 60m, former Olympic 100m champion...  sports  \n",
       "2  Klinsmann added: \"If he is not playing regular...  sports  \n",
       "3  Williams was also far from content.Davenport d...  sports  \n",
       "4  Kenteris's lawyer, Gregory Ioannidis, said: \"T...  sports  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Title']= \"sports\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca18a049-b7a8-445c-bb0f-9388dbf7f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "News       0\n",
       "Summary    0\n",
       "Title      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913779c4-81c6-4bf7-9739-914c02fb6290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['News', 'Summary', 'Title'],\n",
       "    num_rows: 511\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset= Dataset.from_pandas(data)\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b4f2c0-9e52-499c-8fef-7503ff7a45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['News', 'Summary', 'Title'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['News', 'Summary', 'Title'],\n",
       "        num_rows: 103\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data = final_dataset.train_test_split(test_size=0.2)\n",
    "nlp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d86a2485-b503-4963-80c4-7a7bc99e8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a157387-7487-48e3-9f0d-8b7db08bcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"News\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"Summary\"], max_length=224, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1016977-87cb-4be6-a716-fea07c6c99bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5af48ef52ac488ab3f9e4fc3af7b23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e5e810a5c34a73a3af552a751b2d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = nlp_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68978fe0-21d3-4a99-b4e0-4f3bc5a90c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0baf217a-38ec-4484-80e7-9611b9978a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb3bb37-5ff9-41f8-af10-7dd6262534ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8671fdb-b6f9-48b5-87b3-3c43b3302b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"Fine-tuned-t5-text-summarizer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=50,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f3e294c-cdf6-4051-bb65-b847a3d5cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args= training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55bee454-ded5-4d7a-81ff-8a413a35a4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2550/2550 49:32, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530813</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471549</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.457654</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.445636</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.446514</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450587</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.456941</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.461430</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.466810</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.176800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.474451</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.485518</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.493250</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.514170</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.522516</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.523725</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.534553</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.540952</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.547810</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.553075</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.564865</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.568926</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.583567</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.580836</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.588520</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.593395</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.601954</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.614169</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.619559</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.623423</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.624289</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.640691</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.643484</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.646953</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.649534</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.651074</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.655501</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.658013</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.656959</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.653956</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.654611</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.659003</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.657586</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.659077</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.658769</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.659359</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p_r_prod/miniconda3/envs/text2image/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2550, training_loss=0.17994484265645344, metrics={'train_runtime': 2982.2924, 'train_samples_per_second': 6.84, 'train_steps_per_second': 0.855, 'total_flos': 1.237094148685824e+16, 'train_loss': 0.17994484265645344, 'epoch': 50.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "862cf7ca-e736-4b7e-8646-63b64cf9f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text= \" summarize: Why is this deal historic?\\\n",
    "It is just another club for Lionel Messi to go to and show his skills but it is indeed \\\n",
    "historic for the MLS and American Football as a whole. This will bring them the most eyeballs \\\n",
    "they have ever seen. The social media following of Inter Miami has risen by more than 300% and \\\n",
    "the ticket price for all the matches of Inter Miami have gone from $50 to $10,000 . The amount \\\n",
    "of worldwide attention that the MLS will get from this one signing will be humongous.\\\n",
    "Lionel Messi will bring fans to the Stadiums and Inter Miami will have to move \\\n",
    "from their 18,000 seater stadium to the Hard Rock Café Stadium which has a capacity of 70,000 because \\\n",
    "that is the standard of Messi. The sponsors that both Inter Miami and the league will get are \\\n",
    "unfathomable. It is like Michael Jordan playing in the Spanish Basketball League. All the celebrities \\\n",
    "will line up to watch him play and new TV and streaming deals will be made with all the countries around \\\n",
    "the world like India.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40eafdc5-e7bf-4fe6-a536-49e612bae79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb03f238aea04e1999fa9ecb5b45b41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/20.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a78ec9f0ca47c093749511bb4fd517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043e5f519e3a4a3daa70063c51a435db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pranjal0109/Fine-tuned-t5-text-summarizer\")\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2345ac09-8588-4bda-8b65-7122a5a730ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39c337a12964ea690455a387e98cad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbed65e8bb647108fca474ddb433a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"pranjal0109/Fine-tuned-t5-text-summarizer\")\n",
    "outputs = model.generate(inputs, max_new_tokens=500, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03fb670e-7f5d-4893-896a-a5333e5d803a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sponsors that both Inter Miami and the league will get are unfathomable.Lionel Messi will bring fans to the Stadiums and Inter Miami will have to move from their 18,000 seater stadium to the Hard Rock Café Stadium which has a capacity of 70,000 because that is the standard of Messi.The social media following of Inter Miami has risen by more than 300% and the ticket price for all the matches of Inter Miami have gone from $50 to $10,000.It is just another club for Lionel Messi to go to and show his skills but it is indeed historic for the MLS and American Football as a whole.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary= tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd952f15-d8e8-40f9-95cf-0d66495a3a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
